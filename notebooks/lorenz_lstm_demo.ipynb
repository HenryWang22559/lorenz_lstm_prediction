{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lorenz System LSTM Predictor Demo\n",
    "\n",
    "This notebook demonstrates the usage of the LSTM-based predictor for the Lorenz system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from lorenz_lstm.lorenz_system import generate_lorenz_data\n",
    "from lorenz_lstm.data import prepare_data_loaders\n",
    "from lorenz_lstm.model import LorenzLSTM\n",
    "from lorenz_lstm.train import train_model\n",
    "from lorenz_lstm.visualization import plot_3d_trajectories, plot_time_series, plot_training_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Lorenz System Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Parameters\n",
    "t_span = (0, 30)\n",
    "base_initial_xyz = [1, 1, 1]\n",
    "num_trajectories = 200\n",
    "perturbation_scale = 10\n",
    "num_points = 3000\n",
    "\n",
    "# Generate data\n",
    "lorenz_data, t_eval = generate_lorenz_data(\n",
    "    t_span, base_initial_xyz, num_trajectories,\n",
    "    perturbation_scale, num_points\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "sequence_length = 10\n",
    "batch_size = 500\n",
    "\n",
    "train_loader, val_loader, test_loader = prepare_data_loaders(\n",
    "    lorenz_data, sequence_length, batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize model\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = LorenzLSTM().to(device)\n",
    "\n",
    "# Train\n",
    "num_epochs = 70\n",
    "history = train_model(model, train_loader, val_loader, num_epochs, device=device)\n",
    "\n",
    "# Plot training history\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Generate and Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Parameters for prediction\n",
    "num_test_trajectories = 3\n",
    "num_predictions = 200\n",
    "\n",
    "actual_trajectories = []\n",
    "predicted_trajectories = []\n",
    "initial_sequences = []\n",
    "\n",
    "# Get test sequences\n",
    "test_data = lorenz_data[-test_size:]\n",
    "for i in range(num_test_trajectories):\n",
    "    initial_sequence = torch.tensor(test_data[i][:sequence_length], dtype=torch.float32).unsqueeze(0)\n",
    "    \n",
    "    # We only need one sequence for prediction\n",
    "    current_input = initial_sequence  # Keep batch dimension but use only first sequence\n",
    "    \n",
    "    # Store initial sequence without batch dimension for plotting\n",
    "    initial_sequences.append(test_data[i][:sequence_length])\n",
    "    \n",
    "    # Generate predictions\n",
    "    predictions = []\n",
    "    \n",
    "    for _ in range(num_predictions):\n",
    "        with torch.no_grad():\n",
    "            output = model(current_input)  # Shape: [1, 3]\n",
    "            predictions.append(output[0].cpu().numpy())  # Get the prediction for the single sequence\n",
    "            \n",
    "            # Reshape output to match current_input dimensions [1, 1, 3]\n",
    "            next_step = output.view(1, 1, 3)\n",
    "            \n",
    "            # Update input sequence for next prediction\n",
    "            current_input = torch.cat([current_input[:, 1:], next_step], dim=1)\n",
    "    \n",
    "    predicted_trajectory = np.array(predictions)\n",
    "    \n",
    "    # Get corresponding actual trajectory\n",
    "    actual_trajectory = test_data[i]  # Use last few trajectories\n",
    "    actual_trajectory = actual_trajectory[:num_predictions + sequence_length]\n",
    "    \n",
    "    actual_trajectories.append(actual_trajectory)\n",
    "    predicted_trajectories.append(predicted_trajectory)\n",
    "\n",
    "# Convert to numpy arrays for consistent handling\n",
    "actual_trajectories = np.array(actual_trajectories)\n",
    "predicted_trajectories = np.array(predicted_trajectories)\n",
    "initial_sequences = np.array(initial_sequences)\n",
    "\n",
    "# Plot 3D trajectories\n",
    "plot_3d_trajectories(actual_trajectories, predicted_trajectories, initial_sequences)\n",
    "\n",
    "# Plot time series\n",
    "plot_time_series(t_eval, actual_trajectories[0], predicted_trajectories[0], sequence_length)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lorenz_lstm",
   "language": "python",
   "name": "lorenz_lstm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
